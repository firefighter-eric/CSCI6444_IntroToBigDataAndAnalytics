---
title: "R Notebook"
output:
  pdf_document: default
---
```{r}
library(gdata)
library(tm)
```



```{r}
# text = scan("TarzanOfTheApes.txt", what = character(0), sep = "\n", encoding="UTF-8")


setwd('./data')
getwd()
TarzanOfTheApes = VCorpus(DirSource(".", ignore.case = TRUE, mode = "text", encoding="UTF-8"))
ttext = TarzanOfTheApes[[1]]
text = ttext[[1]]
```
## split to chapter
```{r}
chapters = list()
chapter_idx = 0

concentrate <- function(start, end) {
  s = paste(text[start:end], collapse = "")
  gsub("\"", " ", s)
}

for (i in 1: length(text)) {
  if (startsWith(text[i], "Chapter")) {
    if (chapter_idx > 0){
      chapters[[chapter_idx]] = concentrate(line_flag, i)
    }
    chapter_idx = chapter_idx + 1
    line_flag = i + 1
  }

  if (startsWith(text[i], "father was.")){
    chapters[[chapter_idx]] = concentrate(line_flag, i)
    break
  }
}

```

## 10 longest words

```{r}
words = list()
for (chapter in chapters) {
  tmp = strsplit(chapter, " ")
  for (word in tmp)
    words = append(words, word)
}
words = unique(words)

words_length = lapply(words, nchar)
word_index = order(unlist(words_length), decreasing = TRUE)[1:10]
words[word_index]

```

## 10 longest sentences 
```{r}
sentences = list()
for (chapter in chapters) {
  tmp = strsplit(chapter, "w")
  for (sent in tmp)
    sentences = append(sentences, sent)
}

sentence_length = lapply(sentences, nchar)
sentence_index = order(unlist(sentence_length), decreasing = TRUE)[1:10]
sentences[sentence_index]
```
