---
title: "R Notebook"
output:
  pdf_document: default
---
```{r}
library(gdata)
library(tm)
library(wordcloud)
library(ngram)
```


## load text
```{r}
setwd('./data')
getwd()
TarzanOfTheApes = VCorpus(DirSource(".", ignore.case = TRUE, mode = "text", encoding="UTF-8"))
ttext = TarzanOfTheApes[[1]]
text = ttext[[1]]
```
## split to chapter
```{r}
chapters = list()
chapter_idx = 0

concentrate <- function(start, end) {
  s = paste(text[start:end], collapse = " ")
}

for (i in 1: length(text)) {
  if (startsWith(text[i], "Chapter")) {
    if (chapter_idx > 0){
      chapters[[chapter_idx]] = concentrate(line_flag, i)
    }
    chapter_idx = chapter_idx + 1
    line_flag = i + 1
  }

  if (startsWith(text[i], "father was.")){
    chapters[[chapter_idx]] = concentrate(line_flag, i)
    break
  }
}

```


## 10 longest words
```{r}
words = list()
for (chapter in chapters) {
  tmp = strsplit(chapter, "[.?!, -]")
  for (word in tmp)
    words = append(words, word)
}
words = unique(words)

words_length = lapply(words, nchar)
word_index = order(unlist(words_length), decreasing = TRUE)[1:10]
words[word_index]

```

## 10 longest sentences 
```{r}
sentences = list()
for (chapter in chapters) {
  tmp = strsplit(chapter, "[.?!]")
  for (sent in tmp)
    sentences = append(sentences, sent)
}

sentence_length = lapply(sentences, nchar)
sentence_index = order(unlist(sentence_length), decreasing = TRUE)[1:10]
sent10 = sentences[sentence_index]
```
## dendrogram
```{r}
removeNumPunct = function(x) gsub("[^[:alpha:][:space:]*]", "", x)
TarzanCl = tm_map(TarzanOfTheApes, tm::content_transformer(removeNumPunct))
TarzanLow<-tm_map(TarzanCl, tm::content_transformer(tolower))

myStopwords = c(tm::stopwords("english"))
TarzanStop = tm::tm_map(TarzanLow, tm::removeWords, myStopwords)

TarzanStopTDM = tm::TermDocumentMatrix(TarzanStop)
freqTerms = tm::findFreqTerms(TarzanStopTDM, lowfreq=5)

Tarzantf = tm::termFreq(TarzanStop[[1]])

Tarzandf = as.data.frame(TarzanStopTDM[[1]])
TarzanDist = dist(Tarzandf)
TarzanDG = hclust(TarzanDist, method="ward.D2")
# str(TarzanDG)
plot(TarzanDG)
```

```{r}
# words = names(Tarzantf)
# pal = brewer.pal(9, "BuGn")
# TarzanWC = wordcloud(words, Tarzantf, colors = pal[-(1:4)])
```

## ngram
```{r}
tmp = sentences[sentence_index]
sentences10 = " "
for (i in 1:10) {
  sentences10 = paste(sentences10, tmp[[i]], " <end> ")
}

tmp = strsplit(sentences10, "[.?!, -]")
sent_split = list()
s = ""
count = 0
for (word in tmp[[1]]) {
  # word = tmp[[word_idx]]
  # print(word)
  
  if (nchar(word) > 6) {
    s = paste(s, " ", word)
    count = count + 1
  } else if (s != "") {
    sent_split = append(sent_split, s)
    s = ""
  }
}
# ng2
sent_ng = paste(sent_split, " <end> ")
ng2 = ngram(sent_ng, 1)
print(ng2, output="truncated")
```

## ng3
```{r}
ng3 = ngram(sent_ng, 2)
print(ng3, output="truncated")
```

